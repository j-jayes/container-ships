---
title: "ship-scraper"
author: "JJayes"
date: "28/03/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message = F, warning = F)

library(pacman)
p_load(tidyverse, rvest, glue, lubridate)

theme_set(theme_light())

```

### Purpose

I want to scrape information about cargo and container ships from wikipedia and make a shiny app out of it so that people can see how big ships have become.

### Planning

I will start with two sections. One being wikipedia's list of cargo ships. The second is wikipedia's list of largest ships by gross tonnage.

### List of cargo ships scraper

Wikipedia's list of cargo ships past and present includes ships which carry small numbers of passengers in addition to their primary freight cargo.

It looks like this:

![Wikipedia screenshot](images/wikipedia_list_of_cargo_ships.png)

#### Scraping

The scraper first gets the links for all of the articles from the list

```{r}
link <- "https://en.wikipedia.org/wiki/List_of_cargo_ships"

# function that gets the urls for each page from the list
get_ad_links <- function(link){
  html <- read_html(link)
  
  # nice little message
  message(glue("Getting links from {link}"))
  
  html %>% 
    # this html node is found with the selector gadget tool.
    html_nodes("#mw-content-text li a") %>% 
    # gets the links or href
    html_attr("href") %>% 
    # stores them as a tibble, very convenient
    as_tibble()
    
}

# apply function to link.
list_of_links <- get_ad_links(link)

# the problem is that there are multiple instances of the toc links, "#A", "#B" etc. We will filter these out
list_of_links <- list_of_links %>% 
  filter(nchar(value) > 4) %>% 
  # this sticks the stub to the link so that we can use it later
  mutate(value = str_c("https://en.wikipedia.org/", value)) %>% 
  select(url = value)
  
```

Now that we have the list of links we can get the data about each ship from the page.

We want it's date of launch, it's type, tonnage, length, beam and speed.

```{r}
url <- "https://en.wikipedia.org//wiki/Algorail"

get_ship_info <- function(url){
  # store the html from the page
  html <- read_html(url)
  # nice message so that we can see progress.
  message(glue("Getting info from {url}"))
  
  data <- html %>% 
    html_node(".infobox") %>% 
    html_table() %>% 
    rename(title = X1,
           value = X2)
  
  data
  
}

```

### Scraping each page

```{r}

# mapping through each url
df <- list_of_links %>%
        # the possibly statement here means that we will record if there is a failure, for example if there is no infobox in an article.
        mutate(text = map(url, possibly(get_ship_info, "failed")))

df <- df %>% 
  # first we remove the ships that failed.
  unnest(text) %>% 
  filter(is.na(text)) %>% 
  select(-text) %>% 
  filter(title %in% c("Name:",
           "Launched:",
           "Status:",
           "Tonnage:",
           "Length:",
           "Beam:")) %>% 
  mutate(value = str_squish(value)) %>% 
  # then we pivot wider so that each ship is one row
  pivot_wider(names_from = title) %>% 
  # cleaning the names makes it easier to use these columns later
  janitor::clean_names()

write_rds(df, "data/cargo_ship_info.rds")

```

What does the dataset look like?

```{r}

df %>% 
  mutate()

df[2] %>% unlist()

```


### Largest ships by gross tonnage

```{r}

url <- "https://en.wikipedia.org/wiki/List_of_largest_ships_by_gross_tonnage"

html <- read_html(url)

table <- html %>% 
  html_nodes(".sortable") %>% 
  html_table()

table <- table[[1]]

table <- table %>% 
  janitor::clean_names() %>% 
  mutate(across(length:gross_tonnage, parse_number),
         type = as.factor(type))

```

### Flag for ever given

```{r}
table <- table %>% 
  mutate(flag = if_else(name == "Ever Given", 1, 0)) %>% 
  filter(type != "Crane vessel")
```

## How big is the Ever Given in comparison to other large ships?

```{r}

table %>% 
  ggplot(aes(length, gross_tonnage, colour = type, group = 1)) +
  geom_smooth(method = "lm", se = T, colour = "grey50") +
  geom_point() +
  geom_text(data = table %>% filter(flag == 1), aes(label = name), show.legend = F) +
  scale_x_continuous(guide = guide_axis(check.overlap = T)) +
  scale_y_continuous(labels = scales::number_format()) +
  labs(x = "Length (m)",
       y = "Gross tonnage",
       colour = "Type")

```

It is large, among the longest container ships. However we can see that there are some supertankers which are both longer and have much greater capacity. Even the cruis ships in our data set are larger in gross tonnage.

### What about the other features of largeness?

```{r}

table_facet <- table %>% 
  pivot_longer(length:draft, names_to = "feature", values_to = "value") %>% 
  mutate(feature = str_to_title(feature)) %>% 
  mutate(feature = factor(feature, levels = c("Length", "Draft", "Beam")))
  
table_facet %>%   
  ggplot(aes(value, gross_tonnage, colour = type, group = 1)) +
  geom_smooth(method = "lm", se = T, colour = "grey50") +
  geom_point() +
  geom_point(data = table_facet %>% filter(flag == 1), 
             aes(shape = name), 
             cex = 10,
             show.legend = T) +
  geom_text(data = table_facet %>% filter(flag == 1),
            aes(label = name), show.legend = F, colour = "grey25", size = 3) +
  scale_shape_manual(values = 18) +
  scale_x_continuous(guide = guide_axis(check.overlap = T)) +
  scale_y_continuous(labels = scales::number_format()) +
  facet_wrap(~ feature, scales = "free_x") +
  labs(x = "Value (m)",
       y = "Gross tonnage",
       colour = "Type",
       shape = "Highlight")

```

Here we can see that the Ever given has about average draft and beam for it's gross tonnage.

